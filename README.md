# ğŸ™ï¸ AI Voice Assistant â€“ Whisper + Cohere + TTS

This project is a simple voice assistant pipeline that:

1. ğŸ§ Converts voice input to text using OpenAI Whisper
2. ğŸ§  Sends the transcribed text to Cohere LLM to generate a smart response (in Arabic)
3. ğŸ”Š Converts the AI response to spoken voice using pyttsx3

---

## ğŸš€ Features

- ğŸ¤ Input: Audio file (`.mp3`)
- ğŸ“ Transcription: Done using Whisper (`base` model)
- ğŸ§  Smart reply: Generated via Cohere's LLM (supports Arabic)
- ğŸ”Š TTS output: Uses pyttsx3 to read the reply aloud
- ğŸ’¡ Fully scriptable and modifiable for your own AI voice assistant

---

## ğŸ“¦ Requirements

Install required packages using pip:
pip install openai-whisper
pip install cohere
pip install pyttsx3

> âœ… Make sure your system has Python 3.10 or 3.12 (avoid Anaconda if facing audio issues).

---

## ğŸ“ File Structure
project/
â”‚
â”œâ”€â”€ AI.py                # Main Python script
â”œâ”€â”€ hi there.mp3         # Example input audio file
â”œâ”€â”€ README.md            # Project description

---

## ğŸ”§ How It Works

### 1. ğŸ§ Speech Recognition via Whisper

The script loads a Whisper model and transcribes the audio:
model = whisper.load_model("base")
result = model.transcribe(file_path)

### 2. ğŸ§  Response Generation via Cohere

The text is sent to Cohere for Arabic-language reply generation:
response = co.generate(
    model='command',
    prompt=text + "\nØ§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.",
    max_tokens=200
)

### 3. ğŸ”Š Text-to-Speech via pyttsx3

The AI-generated response is spoken aloud:
engine.say(sentence)
engine.runAndWait()

---

## ğŸ§ª Usage

### 1. Place your audio file (e.g., `hi there.mp3`) in the same folder as the script.

### 2. Open a terminal and run:
python AI.py

You should see:
- Transcribed text printed
- AI response in Arabic
- Audio response played through speakers

---
